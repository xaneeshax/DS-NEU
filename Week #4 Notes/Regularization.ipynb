{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generalizability\n",
    "Refers to an algorithm's ability to give accurate predictions for\n",
    "new, previously unseen data\n",
    "\n",
    "Assumptions\n",
    "Future unseen data (test set) will have the same properties as the\n",
    "current training sets\n",
    "\n",
    "Models that are accurate on the training set are expected to be accurate\n",
    "on the test set\n",
    "\n",
    "Overfitting:\n",
    "when you have a model that fits a model too closely to the particularities\n",
    "of the training set\n",
    "\n",
    "Underfitting:\n",
    "The model is too simple and it will fail to capture all aspects of and variability\n",
    "in the data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Goal: Optimization\n",
    "We want to improve the accuracy while avoiding compromising the complexity\n",
    "of the model and thus generalizability of the algorithm\n",
    "\n",
    "Hyperparameter Tuning allows us to optimize our models aka Optimization / Regularization\n",
    "It's all about choosing parameter values that produce the best possible predictions\n",
    "\n",
    "The complexity of models constructed using an algorithm can be changed by tuning\n",
    "the specific hyperparameters of that algorithm\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "df = pd.DataFrame(digits.data)\n",
    "df['target'] = digits.target\n",
    "\n",
    "features = df.drop('target', axis = 1)\n",
    "target = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the training data: 99.26\n",
      "Prediction accuracy on the test data: 98.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 3000)\n",
    "\n",
    "# select a classifier and change parameters\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "\n",
    "# create the model by fitting the training dataset\n",
    "knn.fit(X = X_train, y = y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "predicted = knn.predict(X = X_test)\n",
    "\n",
    "print('Prediction accuracy on the training data:', format(knn.score(X_train, y_train) * 100, '.2f'))\n",
    "print('Prediction accuracy on the test data:', format(knn.score(X_test, y_test) * 100, '.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Support Vector Machines\n",
    "\n",
    "The strength of the regularization, or tuning, is determined by C\n",
    "By default C = 1\n",
    "\n",
    "Larger Values of C : Less Regularization\n",
    "- Fit the training data as well as possible\n",
    "- Each individual data point is important to classify correctly\n",
    "- Increased model complexity\n",
    "\n",
    "Smaller Values of C : More Regularization\n",
    "- More tolerant of errors on individual data points\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the training data: 98.74\n",
      "Prediction accuracy on the test data: 96.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 3000)\n",
    "\n",
    "# select a classifier\n",
    "# As you decreace C the model becomes more simplified\n",
    "model = LinearSVC(random_state = 3000, max_iter = 1000000, C = 0.001)\n",
    "\n",
    "# create a model by fitting the training data\n",
    "model.fit(X = X_train, y = y_train)\n",
    "\n",
    "print('Prediction accuracy on the training data:', format(model.score(X_train, y_train) * 100, '.2f'))\n",
    "print('Prediction accuracy on the test data:', format(model.score(X_test, y_test) * 100, '.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Decision Trees Tuning:\n",
    "\n",
    "max_depth : controls the maximum depth (number of split points)\n",
    "--> Most common way to reduce tree complexity and overfitting\n",
    "\n",
    "Increasing max_depth leads to increased model complexity\n",
    "--> more likely to overfit\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the training data: 97.92\n",
      "Prediction accuracy on the test data: 83.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 3000)\n",
    "\n",
    "# select a classifier\n",
    "# As you decreace C the model becomes more simplified\n",
    "model = DecisionTreeClassifier(max_depth = 10)\n",
    "\n",
    "# create a model by fitting the training data\n",
    "model.fit(X = X_train, y = y_train)\n",
    "\n",
    "# make a prediction on the test set\n",
    "predicted = model.predict(X = X_test)\n",
    "\n",
    "print('Prediction accuracy on the training data:', format(model.score(X_train, y_train) * 100, '.2f'))\n",
    "print('Prediction accuracy on the test data:', format(model.score(X_test, y_test) * 100, '.2f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
