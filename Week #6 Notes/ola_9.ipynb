{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"game_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[\"comment\"]\n",
    "target = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Includes phrases length of: [1]\n",
      "Min_df: 4\n",
      "Classification accuracy on training set:  0.8811618489037844\n",
      "Classification accuracy on testing set:  0.8\n",
      "Number of features used:  10198\n",
      "Includes phrases length of: [1]\n",
      "Min_df: 5\n",
      "Classification accuracy on training set:  0.875366568914956\n",
      "Classification accuracy on testing set:  0.802303664921466\n",
      "Number of features used:  8369\n",
      "Includes phrases length of: [1]\n",
      "Min_df: 6\n",
      "Classification accuracy on training set:  0.8699204021784667\n",
      "Classification accuracy on testing set:  0.806282722513089\n",
      "Number of features used:  7212\n",
      "Includes phrases length of: [1, 2]\n",
      "Min_df: 4\n",
      "Classification accuracy on training set:  0.9252897639994414\n",
      "Classification accuracy on testing set:  0.829738219895288\n",
      "Number of features used:  36069\n",
      "Includes phrases length of: [1, 2]\n",
      "Min_df: 5\n",
      "Classification accuracy on training set:  0.9162826420890937\n",
      "Classification accuracy on testing set:  0.8272251308900523\n",
      "Number of features used:  28068\n",
      "Includes phrases length of: [1, 2]\n",
      "Min_df: 6\n",
      "Classification accuracy on training set:  0.9081133919843597\n",
      "Classification accuracy on testing set:  0.8251308900523561\n",
      "Number of features used:  23108\n",
      "Includes phrases length of: [1, 2, 3]\n",
      "Min_df: 4\n",
      "Classification accuracy on training set:  0.9307359307359307\n",
      "Classification accuracy on testing set:  0.8303664921465969\n",
      "Number of features used:  49652\n",
      "Includes phrases length of: [1, 2, 3]\n",
      "Min_df: 5\n",
      "Classification accuracy on training set:  0.920262533165759\n",
      "Classification accuracy on testing set:  0.8312041884816754\n",
      "Number of features used:  37412\n",
      "Includes phrases length of: [1, 2, 3]\n",
      "Min_df: 6\n",
      "Classification accuracy on training set:  0.9107666527021365\n",
      "Classification accuracy on testing set:  0.8295287958115183\n",
      "Number of features used:  30137\n",
      "Includes phrases length of: [1, 2, 3, 4]\n",
      "Min_df: 4\n",
      "Classification accuracy on training set:  0.9308755760368663\n",
      "Classification accuracy on testing set:  0.8289005235602094\n",
      "Number of features used:  53055\n",
      "Includes phrases length of: [1, 2, 3, 4]\n",
      "Min_df: 5\n",
      "Classification accuracy on training set:  0.9205418237676303\n",
      "Classification accuracy on testing set:  0.829109947643979\n",
      "Number of features used:  39479\n",
      "Includes phrases length of: [1, 2, 3, 4]\n",
      "Min_df: 6\n",
      "Classification accuracy on training set:  0.9115347018572825\n",
      "Classification accuracy on testing set:  0.8278534031413612\n",
      "Number of features used:  31559\n",
      "Includes phrases length of: [1, 2, 3, 4, 5]\n",
      "Min_df: 4\n",
      "Classification accuracy on training set:  0.9308057533863986\n",
      "Classification accuracy on testing set:  0.8278534031413612\n",
      "Number of features used:  53642\n",
      "Includes phrases length of: [1, 2, 3, 4, 5]\n",
      "Min_df: 5\n",
      "Classification accuracy on training set:  0.9204720011171624\n",
      "Classification accuracy on testing set:  0.8286910994764398\n",
      "Number of features used:  39822\n",
      "Includes phrases length of: [1, 2, 3, 4, 5]\n",
      "Min_df: 6\n",
      "Classification accuracy on training set:  0.9115347018572825\n",
      "Classification accuracy on testing set:  0.8289005235602094\n",
      "Number of features used:  31786\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Unigrams, Bigrams, Trigrams, 4-Grams & 5-Grams\n",
    "'''\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "\n",
    "        #create the vocabulary based on the training data\n",
    "        vect = TfidfVectorizer(min_df = j + 4, ngram_range = (1,(i+1))).fit(X_train)\n",
    "\n",
    "        #encode the words in X_train and X_test based on the vocabulary\n",
    "        X_train_vectorized = vect.transform(X_train)\n",
    "        X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "        #train the classifier\n",
    "        model = MultinomialNB(alpha = 0.5).fit(X=X_train_vectorized, y = y_train)\n",
    "\n",
    "        print('Includes phrases length of:', [i + 1 for i in range(i + 1)])\n",
    "        print('Min_df:', j + 4)\n",
    "        print(\"Classification accuracy on training set: \", model.score(X_train_vectorized, y_train))\n",
    "        print(\"Classification accuracy on testing set: \", model.score(X_test_vectorized, y_test))\n",
    "        print(\"Number of features used: \", len(vect.get_feature_names()), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The combination that yielded the best result was using unigrams, bigrams, and trigrams with \n",
    "a minimum number of document appearances of 5\n",
    "\n",
    "Includes phrases length of: [1, 2, 3]\n",
    "Min_df: 5\n",
    "Classification accuracy on training set:  0.920262533165759\n",
    "Classification accuracy on testing set:  0.8312041884816754\n",
    "Number of features used:  37412\n",
    "\n",
    "As the number of n_grams increased, there was more overfitting as the model performed far better\n",
    "on the training set and worse on the testing sets.\n",
    "\n",
    "The effect of slightly increasing the min_df had a very small impact on the training set accuracy\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
